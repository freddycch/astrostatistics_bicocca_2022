{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the latest database of Gamma Ray Bursts.\n",
    "\n",
    " - The database can be downloaded at https://user-web.icecube.wisc.edu/~grbweb_public/Summary_table.txt\n",
    " - You can find the physical meaning of each variable at https://user-web.icecube.wisc.edu/~grbweb_public/Variables.html \n",
    "\n",
    "\n",
    "This edition of \"get your hands dirty\" is very open ended (we're getting closer and closer to real research here!). You have a cool dataset, explore it! Play with the data, apply some of the tecniques we have seen in classes so far, etc. **Be creative! You're discovering**\n",
    "\n",
    "\n",
    "Some relevant physical questions you might want to tackle include:\n",
    "\n",
    "- Does the distribution contain different sub-populations? How many?\n",
    "- What's the threshold between the classes?\n",
    "- If you try two clustering methods, do you get more or less the same?\n",
    "- How do methods respond to outliers?\n",
    "- What variable(s) shows the multi-modality more evidently?\n",
    "- Are all GRBs equally likely to be observed? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [8,8]\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Download file\n",
    "r = requests.get('https://user-web.icecube.wisc.edu/~grbweb_public/Summary_table.txt')\n",
    "with open(\"Summary_table.txt\", 'wb') as f:\n",
    "    f.write(r.content)\n",
    "\n",
    "# Read content\n",
    "raw_data = np.loadtxt(\"Summary_table.txt\", dtype='str', unpack='True')\n",
    "\n",
    "# Read headers\n",
    "with open(\"Summary_table.txt\",'r') as f:\n",
    "    names= np.array([n.strip().replace(\" \",\"_\") for n in f.readlines()[1].replace(\"#\",\"\").replace(\"\\n\",\"\").lstrip().split('    ') if n.strip()!=''])\n",
    "\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw_df = pd.DataFrame(raw_data.T, columns=names)\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def drop_errors(df, col):\n",
    "    idx = df[ df[col] == '-999' ].index \n",
    "    #print(idx)\n",
    "    df.drop(idx, inplace=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\"\"\"\n",
    "def drop_errors(df, cols):\n",
    "    for col in cols:\n",
    "        print(col)\n",
    "        idx = df[ df[col] == '-999' ].index\n",
    "        df.drop(idx, inplace=True)\n",
    "        df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Does the distribution contain different sub-populations? How many?\n",
    "- What's the threshold between the classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### T90 ANALYSIS\n",
    "\n",
    "df = drop_errors(raw_df, ['T90'])\n",
    "\n",
    "T90 = np.log( df['T90'].to_numpy(dtype=float) )\n",
    "\n",
    "tBins = np.linspace(-4,7,40)\n",
    "_ = plt.hist(T90, bins=tBins, color='slateblue', density=True, alpha=0.5)\n",
    "_ = plt.title('T90 distribution of GRBs')\n",
    "#_ = plt.axvline(2, c='slateblue', ls='-.')\n",
    "\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gm = GaussianMixture(n_components=2, random_state=5, covariance_type='spherical').fit(T90.reshape(-1,1))\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "params = np.array( [np.flip(gm.weights_, axis=0),\n",
    "                    np.flip( np.squeeze( gm.means_), axis=0 ),\n",
    "                    np.flip( np.sqrt(gm.covariances_), axis=0 ) ] ).T\n",
    "\n",
    "gauss = lambda x, mu, rms : norm(mu,rms).pdf(x)\n",
    "\n",
    "x = np.linspace(-6,8,150)\n",
    "colors = ['navy', 'royalblue']\n",
    "for [w, mu, rms], color in zip(params[:], colors):\n",
    "    cut = lambda x : np.around(x,2)\n",
    "    tag = r'$( \\ \\mu \\ , \\sigma \\ )=( \\ $' + str(cut(mu)) + '$, \\ $' + str(cut(rms)) +'$ \\ )$'\n",
    "    plt.plot(x, w*gauss(x,mu,rms), c=color, label=tag, ls='--')\n",
    "    plt.axvline(mu, c=color, ls=':')\n",
    "    \n",
    "plt.legend(ncol=2, loc='center')\n",
    "plt.figure(figsize=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FLUENCE ANALYSIS\n",
    "\n",
    "df = drop_errors(raw_df, ['fluence'])\n",
    "FLUENCE = df['fluence'].to_numpy(dtype=float)\n",
    "\n",
    "fBins = np.logspace(-9,-2,50)\n",
    "plt.hist(FLUENCE, bins=fBins)\n",
    "plt.xscale('log')\n",
    "#plt.scatter(T90, FLUENCE)\n",
    "#plt.yscale('symlog')\n",
    "#plt.ylim([10**-3,10**-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If you try two clustering methods, do you get more or less the same?\n",
    "- How do methods respond to outliers?\n",
    "- What variable(s) shows the multi-modality more evidently?\n",
    "- Are all GRBs equally likely to be observed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = drop_errors(raw_df,['T90','fluence'])\n",
    "\n",
    "T90 = df['T90'].to_numpy(dtype=float)\n",
    "FLUENCE = df['fluence'].to_numpy(dtype=float)\n",
    "\n",
    "print('Scattering!')\n",
    "plt.scatter(T90, FLUENCE, marker='.', s=1.5, color='royalblue')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.ylim([10**-10,10**-2])\n",
    "plt.xlim([10**-2,10**3.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#print(T90)\n",
    "#print(FLUENCE)\n",
    "for t, f in zip(T90,FLUENCE[:3]):\n",
    "    print([t,f])\n",
    "data = np.array( [ [t,f] for t,f in zip( T90, FLUENCE ) ] )\n",
    "data = np.newaxis(data,None)\n",
    "clf = KMeans(n_clusters = 2)\n",
    "#clf.fit(data)\n",
    "# centers = clf.cluster_centers_\n",
    "# print(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
