{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4e24bf8",
   "metadata": {},
   "source": [
    "Guardiamo la seconda parte del SN coding assignment. \n",
    "\n",
    "Fa GPR: il fit è illustrato nel notebook. Ci sono *sei* hyperparameters! **FAI CROSS-VALIDATION!**\n",
    "\n",
    "La GPR dà anche incertezza sul fit. Not bad. Conclusioni: la GPR non è sempre praticabile.\n",
    "\n",
    "Fa *parametric fit*: recap solito. Fa' Bayesian Fit! Fa' anche Frequentist Fit (con che assumptions?)!\n",
    "\n",
    "Stimo $\\mu(z)$ -> uso astropy.cosmology per calcolare quell'integrale.\n",
    "\n",
    "Fa un MCMC (5-10 min) -> setup, run tutto presente nella soluzione.\n",
    "\n",
    "Corner plot: H0 e Omega_Matter assumendo k=0.\n",
    "\n",
    "Fa nested sampling, per controllare se viene lo stesso risultato. Trasforma la prior, usa dynesty. Ok, sembra convergere. Poco denso at alto -lnX, forse devi aumentare accuracy nel fit // far andare il codice più a lungo, per migliorare il risultato.\n",
    "\n",
    "Output: un altro corner plot, suspiciously similar a quel che ho fatto prima. \n",
    "\n",
    "Plot: multiple realizations from the model (curve rosse)\n",
    "\n",
    "Molto bene, ho misurato parametri cosmologici da SN data.\n",
    "\n",
    "*Is there any dark energy?*\n",
    "\n",
    "FORZO Omega_Lambda = 0 -> Il mio corner plot è un istogramma, ma come fitto i dati? Anche senza Dark Energy, non stai fittando male!!! Infatti se confronti i modelli, hai un 2 (VERY SMALL!)\n",
    "\n",
    "Chiaramente, il problema è che NON HAI I PUNTI AD ALTO z SU CUI FITTARE, e A BASSO REDSHIFT OGNI MODELLO \"VEDE\" LA STESSA COSA.\n",
    "\n",
    "Generiamo dei punti a caso e vediamo se spunta la Dark Energy?\n",
    "\n",
    "Genero **mock data** -> random draws from nested sampling, e altri da GPR. BEH, diciamo che il modo in cui fa i random draws è molto più raffinato di quello visto all'inizio. Il metodo in giallo è estremamente data-driven, quello in blu fa delle assunzioni sull'universo.\n",
    "\n",
    "> Abbiamo visto il fitting in modo frequentista, il fitting in modo bayesiano, e ora abbiamo visto il fitting da un punto di vista puramente di machine learning. Direi che abbiamo finito.\n",
    "\n",
    "Proposta: prova a fittare per la curvatura dell'universo..?\n",
    "\n",
    "**Sei altamente incoraggiato a fare ulteriori esplorazioni sui dati, al di là di quel che è stato richiesto!**\n",
    "\n",
    "# Classification I\n",
    "\n",
    "**SUPERVISED ML**. Voglio classificare i dati: so la truth di pochi oggetti, *labelled* e voglio inferire quella di *unlabelled* object.\n",
    "\n",
    "* **Generative Classification**: what is the most likely category for the object i'm trying to classify? -> alla fine, è Density Estimation; \n",
    "\n",
    "* **Discriminative Classification**: ti interessano i boundaries, tra le regioni di classificazione. Non ti interessa classificare i singoli oggetti. E' più facile e meno ambiziosa dell'altra qui sopra, e a volte è quel che ti basta.\n",
    "\n",
    "##### Assessing Results\n",
    "\n",
    "Cosa significa che una classificazione è buona o cattiva?\n",
    "\n",
    "Supponiamo di fare un covid test: il risultato sarà uno tra true positive, false positive, true negative, false negative.\n",
    "\n",
    "Ciascun risultato ha una probabilità. Ci sono un po' di definizioni nel notebook:\n",
    "\n",
    "* completeness: probabilità di trovare qualcosa di vero\n",
    "* contamination: probabilità di trovare qualcosa di falso\n",
    "* efficiency = precision = 1-contamination\n",
    "\n",
    "Supponiamo di cercare qualcosa di super raro: non mi importa avere i falsi positivi, tanto quel che voglio è avere QUELL'evento (es. una SNe estremamente luminosa)\n",
    "\n",
    "Supponiamo invece di cercare qualcosa con altissima precisione: a questo punto, li voglio sottoterra\n",
    "\n",
    "> A seconda di cosa cerco, faccio diverse classificazioni con diversi criteri.\n",
    "\n",
    "### Comparing Classifier Performances\n",
    "\n",
    "ROC Curve: vedi notebook. Da quel che ho capito, la sua forma sarà diversa a seconda di cosa vuoi massimizzare.\n",
    "\n",
    "Guarda tutto il blocco di codice: a seconda del threshold, hai una diversa efficiency e completeness. Nota che le due cose sono parecchio collegate!\n",
    "\n",
    "Plot successivo: voglio precision 90%, che precision e recall mi servono?\n",
    "\n",
    "Ok, tutto questo era per True/False e simili. Posso avere anche più di due opzioni, ma non approfondiamo l'argomento.\n",
    "\n",
    "# Generative Classification\n",
    "\n",
    "Basically, boils down to bayes's theorem.\n",
    "\n",
    "Generative classifier: tutto quel che devo fare è *modellare la conditional probability* -> regression / density estimation problem!\n",
    "\n",
    "Come chiamo la discriminant function?\n",
    "\n",
    "* **Discriminant Function**: la conditional probability era l'obiettivo principale della regression. Nel nostro caso, f(y|x) ha *discrete* classes. \n",
    "\n",
    "* **Bayes Classifier**: se voglio solo una prediction, chiamo così la discriminant function\n",
    "\n",
    "* **Decision Boundary**: un set di valori per cui ogni classe è equally likely \n",
    "\n",
    "(?) (?) (?) (?) (?)\n",
    "\n",
    "### Naive Bayes Classifier\n",
    "\n",
    "HP: tutti gli attributi sono *indipendenti*\n",
    "\n",
    "Esempio con due dimensioni: scrive p come il prodotto delle probabilità, e applica la bayes rule.\n",
    "\n",
    "Massimizziamo $\\hat{y}$: mi servono \n",
    "\n",
    "* la frequency of the class k\n",
    "* la probability density di un oggetto di classe k che abbia gli attributi x (è un density estimation problem)\n",
    "\n",
    "#### Gaussian Naive Bayes\n",
    "\n",
    "Qui diventa tutto analitico, e puoi trovare la forma di $\\hat{y}$ indicata. In sklearn è implementato con `GaussianNB`. Trovo il boundary illustrato in figura.\n",
    "\n",
    "Caso più astrofisico: sample di stelle da SDSS. Cerchiamo di estrarre delle stelle molto rare, le \"RL Lyrae Variables\". Sono variable stars, ci fai cose molto interessanti, e sono in verde nel plot. \n",
    "\n",
    "Il codice è in figura. Light points: variable source; dark points: non-variable source. \n",
    "\n",
    "Ok, quale regione è most likely per contenere le mie variable stars? Chiaramente, il mio set non è completo ed è contaminato!\n",
    "\n",
    "> Domanda: che succede se \"tiri su\" la boundary condition \"a mano\"? Che succede a completezza e contaminazione? <br> Che succede invece se aumenti la dimensione del training set..?\n",
    "\n",
    "Droppiamo l'assunzione che i singoli colori siano indipedenti: che succede? \n",
    "\n",
    "### Linear & Quadratic Discriminant Analysis\n",
    "\n",
    "DROPPO l'assunzione che sia tutto indipendente da tutto, ma devo fare delle approssimazioni: butto quel che è più di linear/quadratic nella varianza.\n",
    "\n",
    "Linear boundary, trova linea. Quadratic boundary, trova una curva.\n",
    "\n",
    "**È molto simile al risultato precedente!** Motivo? I filtri dei colori sono abbastanza separati da permettermi di poter effettivamente assumere l'indipendenza dei colori...\n",
    "\n",
    "### GMM and Bayes Classification\n",
    "\n",
    "Alla fine mi sono ridotto a fare density estimation. \n",
    "\n",
    "Gaussian Model: dovevo specificare il numero di gaussiane. Una gaussiana, non basta sicuramente; con cinque colori e cinque gaussiane, va molto meglio!\n",
    "\n",
    "One step further: full KDE approximation! (RIASCOLTA QUESTA PARTE)\n",
    "\n",
    "### K-Nearest Neighbor Classifier\n",
    "\n",
    "Ho visto come si fa a classificare in base ai punti più vicini. Posso farlo anche qui! Ovviamente devi fare pre-processing, e specificare il tipo di distanza tra punti che devi calcolare.\n",
    "\n",
    "Risultato dal notebook: THERE IS SOME OVERFITTING. k=1 è terribile.\n",
    "\n",
    "Come decido qual è il K migliore? -> Cross-Validation! Risultato dal notebook: **8** è il valore migliore. (Nota che ha SCELTO di massimizzare l'accuracy = pochi false positives!)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
