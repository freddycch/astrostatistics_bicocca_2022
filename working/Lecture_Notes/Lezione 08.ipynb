{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAYESIAN INFERENCE\n",
    "\n",
    "Gerry consiglia vivamente di leggere il terzo elemento del primo elenco puntato.\n",
    "\n",
    "Abbiamo già visto le definizioni di *probabilità condizionata* e di *probabilità composta*, e il *teorema di Bayes*.\n",
    "\n",
    "Bayesian approach: quanto visto sopra vale anche per i *parametri* e i *modelli*! \n",
    "\n",
    "Riprendiamo l'heteroscedastic/homoscedastic gaussian exercise: massa di una galassia. Siamo d'accordo nel dire che la massa della galassia non è negativa? Il MLE *resta al suo posto* se ho soppresso la coda < 0! Ehm, ma non va bene! \n",
    "\n",
    "> Prior information can and should affect your inference!\n",
    "\n",
    "Bayesian inference fa esattamente questo: incorporare la mia conoscenza *a priori* nel mio processo di inferenza. \"So che questo è un outlier e lo butto\" -> stai assumendo qualcosa a priori, anche da frequentista!\n",
    "\n",
    "> L'analisi bayesiana fa probability statements anche sui model parameters e sui models themselves\n",
    "\n",
    "Quindi ha senso parlare di \"probabilità della velocità della luce\", o della \"probabilità della meccanica quantistica di essere giusta\". \n",
    "\n",
    "*posterior distribution*: sono i risultati che ottengo. Non hanno a che vedere con gli esperimenti ripetuti, ma concettualmente rappresenta *quanto sono confident che i risultati che ottengo siano giusti*.\n",
    "\n",
    "> Mappare le posterior è un casino, infatti richiede quasi sempre metodi numerici. Si spiega il perché la bayesian analysis sia \"alla moda\" adesso!\n",
    "\n",
    "---\n",
    "\n",
    "La *likelihood* l'ho già definita: p(M|D) è invece la probabilità di un modello, given the data!\n",
    "\n",
    "$$p(M\\,|\\,D) = \\frac{p(D\\,|\\,M)\\,p(M)}{p(D)},$$\n",
    "\n",
    "where $D$ is for data and $M$ is for model. Or in words,\n",
    "\n",
    "$${\\rm Posterior \\,\\, Probability} = \\frac{{\\rm Likelihood}\\times{\\rm Prior}}{{\\rm Evidence}}.$$\n",
    "\n",
    "\n",
    "If we explicitly recognize prior information, $I$, and the model parameters, $\\theta$, then we can write:\n",
    "\n",
    "$$p(M,\\theta \\,|\\,D,I) = \\frac{p(D\\,|\\,M,\\theta,I)\\,p(M,\\theta\\,|\\,I)}{p(D\\,|\\,I)},$$\n",
    "\n",
    "where we will omit the explict dependence on $\\theta$ by writing $M$ instead of $M,\\theta$ where appropriate.  However, as the prior can be expanded to \n",
    "\n",
    "$$p(M,\\theta\\,|\\,I) = p(\\theta\\,|\\,M,I)\\,p(M\\,|\\,I),$$\n",
    "\n",
    "it will still appear in the term $p(\\theta\\,|\\,M,I)$. ( A volte puoi fare questa cosa, se ti serve. )\n",
    "\n",
    "---\n",
    "\n",
    "NOTA CHE LA EVIDENCE NON DIPENDE DAL MODELLO M, quindi è solo una costante di normalizzazione! Fai parameter estimation? Non ti serve tracciare l'evidence. Fai model convergence? Ti serve eccome ed è *difficile* da calcolare, perché devi *integrare* la posterior.\n",
    "\n",
    "---\n",
    "\n",
    "**The Bayesian Statistical Inference process** is then\n",
    "1. formulate the likelihood, $p(D\\,|\\,M,\\theta,I)$\n",
    "2. chose a prior$^1$, $p(M,\\theta\\,|\\,I)$, which incorporates *other information beyond the data in $D$*\n",
    "3. determine the posterior pdf, $p(M,\\theta \\,|\\,D,I)$\n",
    "4. search for the model parameters that maximize $p(M,\\theta \\,|\\,D,I)$ \n",
    "5. quantify the uncertainty of the model parameter estimates\n",
    "6. perform model selection to find the most apt description of the data\n",
    " \n",
    "$^1$: Note that $p(M,\\theta\\,|\\,I) = p(\\theta\\,|\\,M, I)\\, p(M\\,|\\,I)$.  \n",
    "La prior può includere in I un esperimento che hai fatto prima, o delle conoscenze che hai a priori, o altro...\n",
    "\n",
    "Confronta con il concetto di massimizzare la likelihood: è simile, ma è vagamente diverso perché qui dai probabilità anche a modelli e parametri!\n",
    "\n",
    "---\n",
    "\n",
    "Ok, ma perché e quali prior vado ad inserire..? Cosa sono?\n",
    "\n",
    "*Informative* vs. *Uninformative* prior: una è guidata/basata su principi primi,  qualcosa che sta alla base del tuo esperimento. DAGLI APPUNTI SUOI:\n",
    "\n",
    "Priors can be **informative** or **uninformative**.  As it sounds, informative priors are based on existing information (including previously obtained data, but not the data considered right now) that might be available.  Uniformative priors can be thought of as \"default\" priors, i.e., what your prior is when you never used\n",
    "any data, e.g, a \"flat\" prior like $p(\\theta|M,I) \\propto {\\rm C}$.\n",
    "\n",
    "Detailed discussion can be found in Section 5.2 in the textbook. In general, we want our inferences to be ***data dominated*** rather than prior dominated, so we try to use ***weakly-informative priors***. There are three\n",
    "main principles used to choose a prior: \n",
    "\n",
    "\n",
    "### (i) The Principle of Indifference\n",
    "\n",
    "Essentially this means adopting a uniform prior, though you have to be a bit careful.  Saying that an asteroid is equally likely to hit anywhere on the Earth is not the same as saying that all latitudes of impact are equally likely.  \n",
    "\n",
    "Assuming $1/6$ for a six-side die, or $1/2$ for heads and tails of a fair coin, would be an example of indifference.\n",
    "\n",
    "### (ii) The Principle of Invariance (or Consistency)\n",
    "\n",
    "This applies to location and scale invariance.  \n",
    "\n",
    "**Location invariance** suggests a uniform prior, within the accepted bounds: $p(\\theta|I) \\propto 1/(\\theta_{max}-\\theta_{min})$ for $\\theta_{min} \\le \\theta \\le \\theta_{max}$. \n",
    "\n",
    "**Scale invariance** gives us priors that look like $p(\\theta|I) \\propto 1/\\theta$, which implies a uniform\n",
    "prior for ln($\\theta$), i.e. a prior that gives equal weight over many orders of magnitude. \n",
    "\n",
    "### (iii) The Principle of Maximum Entropy\n",
    "\n",
    "We will not discuss it here - for more details, see Section 5.2.2 in the textbook.\n",
    " \n",
    "It is often true that Bayesian analysis and traditional MLE are essentially equivalent.  \n",
    "However, in some cases, considering the priors can have significant consequences, as\n",
    "we will see later. \n",
    "\n",
    "We will skip examples of very steep priors and their consequences called in astronomy\n",
    "literature **Eddington-Malmquist** and **Lutz-Kelker** biases (see Chapter 5 in the textbook\n",
    "if you are interested as well as [here](https://en.wikipedia.org/wiki/Lutz%E2%80%93Kelker_bias)). \n",
    "\n",
    "\n",
    "###### Conjugate Priors\n",
    "\n",
    "= Prior e Posterior arrivano dalla stessa famiglia. Esempio: la gaussiana. \n",
    "\n",
    "Se prior e posterior hanno la stessa forma funzionale, le chiami conjugate priors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyerarchical Bayesian Modelling\n",
    "\n",
    "Che succede se hai una prior che è essa stessa parametrizzata, e chiedi di mappare non solo la posterior ma anche i parametri della prior? C'è praticamente un altro livello di inferenza! -> *hyperparameters*, *hyperpriors* e simili. Un bel macello insomma, ma sembra una gran figata! :°\n",
    "\n",
    "Riascolta gli esempi che fa a lezione! ò_ò\n",
    "\n",
    "---\n",
    "\n",
    "### Bayesian Credible Regions\n",
    "\n",
    "Ho mappato la posterior ( in qualche modo ): voglio estrare summary statistics per capire quanto buona è la mia inferenza. \n",
    "\n",
    "Frequentist approach: confidence intervals. Se faccio un numero enorme di misure, i miei valori cadono nell'intervallo XX% delle volte.\n",
    "\n",
    "Bayesian approach: NON RIPETO L'ESPERIMENTO. CIASCUN ESPERIMENTO E' UN DATA SET A SE'!\n",
    "\n",
    "Posso fare probabilistic statement sui parametri: dato UN data set che ho preso, quanto è probabile che i miei parametri abbiano un determinato valore? \n",
    "\n",
    "-> Massimizzo la posterior?\n",
    "\n",
    "-> Cerco la mediana del mio parametro // credible regions.\n",
    "\n",
    "RIASCOLTA QUESTO PEZZO.\n",
    "\n",
    "*Credible regions are not unique*: si possono calcolare in due modi diversi.\n",
    "\n",
    "1. Parto dal massimo, integro \"in giù\" fino a trovare il 68% delle misure\n",
    "2. Integro dai lati, \"lascio\" un intervallo che includa il 68% delle misure\n",
    "\n",
    "##### Simple Example: Coin Flip\n",
    "\n",
    "Quanto è probabile che mi escano \"testa\" o \"croce\"? Vedi notebook.\n",
    "Aumenti il numero di trials? La posterior è sempre più piccata ( da rinormalizzare ).\n",
    "\n",
    "Supponiamo di usare una diversa prior: cosa succede? \n",
    "\n",
    "> All'aumentare dei dati, passo da *prior dominated* a *data dominated*: è difficile capire \"dove\" sono!\n",
    "\n",
    "### Nuisance Parameters\n",
    "\n",
    "A volte non me ne frega di alcuni dei miei parametri // alcuni sono più importanti di altri. Supponiamo di misurare la QSO position della L05, misuro una $x$ con uno spread gaussiano di qualche tipo.\n",
    "\n",
    "Prendo la mia priori, la fisso uniforme. Assumiamo di *sapere* le sigma_i. Allora so come massimizzare la likelihood, e trovo il mio mu_0, che è uguale all'MLEstimator che so prima.\n",
    "\n",
    "*Assumiamo di non conoscere gli spread*: supponiamo di non sapere la sigma_i, e di volerla misurare dai dati.\n",
    "\n",
    "A questo punto la L cambia! Nota il fattore extra $log(\\sigma)$ in fondo al conto, che non rende più analitico il tuo problema.\n",
    "\n",
    "Posso riparametrizzare usando sample mean e sample variance, ma solo perché i miei dati sono distribuiti in modo gaussiano. \n",
    "\n",
    "Tipico risultato bayesiano: $\\sigma$ vs. $\\mu$, con scala di colore per logL.\n",
    "\n",
    "NOT ALL PARAMETERS ARE CREATED EQUAL: vedi esempio. Marginalize le due posterior distributions. p($\\mu$) è la probabilità di $\\mu$ che tiene in presente la mia *model knowledge*! \"Su tutte le possibilità possibili dei miei dati, chi è $\\mu$?\" ( RIASCOLTA )\n",
    "\n",
    "Ultima figura nel notebook: \n",
    "* blue solid è il risultato bayesiano con la prior analitica che sapevo\n",
    "* purple dotted è il ris. bayesiano con uniform prior e sigma\n",
    "* red dashed è l'analytical maximum likelihood result\n",
    "\n",
    "Nota che sono DIVERSE! GUARDA IL CODICE DIETRO QUESTA IMMAGINE, E' IMPORTANTE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Parameter Estimation Examples\n",
    "\n",
    "*Error*: termine suato in modo molto \"loose\", finora. \n",
    "\n",
    "Vediamo l'esempio che fa adesso\n",
    "1. la distribuzione ha un suo spread.\n",
    "2. la distribuzione che misuro ha un underlying spread: ogni stella in un cluster avrà un errore $e_{i}$. Se gli errori sono tutti uguali, ho una distribuzione gaussiana. Altrimenti NON lo sarà!\n",
    "\n",
    "Il risultato è nel notebook L09. In questo caso, con uniform prior su $\\mu$ e $\\sigma$, succede quello che c'è nel notebook. Allora ok con la somma in quadratura! \n",
    "\n",
    "Errore eteroscedastico? Bene, la mia \"goccia\" si è stortata!\n",
    "* la posterior non è simmetrica! \n",
    "* la posterior è compatibile con l'avere sigma = 0, al 99.7%\n",
    "\n",
    "Prova ad editare il codice e a modificare la N: che succede?\n",
    "\n",
    "---\n",
    "\n",
    "Altro esempio: estimating something out of a background.\n",
    "\n",
    "Creo modello per il picco dentro un background. Likelihood: gaussian + background\n",
    "\n",
    "Posso marginalizzare il background, non mi interessa cosa fa! ( assumo di sapere mu, cerco p(A,sigma) )\n",
    "\n",
    "Trovo correlation tra A e sigma! => very informative: cerchi segnale? La marginalization over the background can be correlated. \n",
    "\n",
    "More realistic example: non so niente -> 4D parameter search, good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Model Comparison\n",
    "\n",
    "Ho fittato il modello: voglio sapere se sia \"il migliore possibile\". Bayesian statistics: non posso dire se il modello è \"buono\" o \"cattivo\", ma posso dire se è \"migliore\" di un altro. \n",
    "\n",
    "Probabilità che un modello sia meglio di un altro: è basata *both* sui current data e sui prior models!\n",
    "\n",
    "Notebook: \"best\" linear, quadratic, cubic models. Faccio il chi2, vedo dei risultati.\n",
    "\n",
    "**Which model should we adopt?** Il chi2 più basso è il migliore per i parametri? Uso Occam's Razor: il minor numero di parametri è il migliore.\n",
    "\n",
    "Decide what model is better with the *odds ratio*. Non è intercambiabile col *bayes factor*, a volte. \n",
    "\n",
    "Odds Ratio: ratio of the evidence. \n",
    "\n",
    "Bayes Factor: ratio of posteriors. Dalla definizione capisci quando è uguale all'odds ratio.\n",
    "\n",
    "Faccio foto al cielo, voglio capire se ho source o background: a seconda di \"dove\" sono nella foto ( al centro di una galassia o completamente sullo sfondo ), lo stesso pixel count può avere un significato diverso! \n",
    "\n",
    "\n",
    "Tabellina molto utile per interpretare i bayes factors: Jeffreys Scale.\n",
    "\n",
    "---\n",
    "\n",
    "## Bayesian Evidence \n",
    "\n",
    "... è il denominatore citato all'inizio. Dimentichiamoci un attimo la model comparison.\n",
    "\n",
    "Misuro i miei parametri theta, dati i dati D e il modello M: allora so già la definizione. \n",
    "\n",
    "~Per fare parameter estimation, va bene anche solo la posterior. Adesso ti serve l'evidence!~\n",
    "\n",
    "Devi mappare la posterior, trovare il massimo e integrarla! E' un bel casino.\n",
    "\n",
    "---\n",
    "\n",
    "##### Ranking Different Models\n",
    "\n",
    "Frequentist: qual è la confidence con cui posso rigettare l'ipotesi nulla?\n",
    "Bayesian: do I need a cosmological constant or not?\n",
    "\n",
    "Attenzione: il rasoio di Occam è automaticamente incorporato e NON sto dicendo QUANTI parametri sto usando! \n",
    "\n",
    "---\n",
    "\n",
    "##### Cauchy vs. Gaussian model comparison\n",
    "\n",
    "Vedi Notebook.\n",
    "\n",
    "##### Coin Flip model comparison\n",
    "\n",
    "Vedi Notebook.\n",
    "\n",
    "M1: mi fido del tipo, b* = 0.5 -> la prior è una delta function in 0.5\n",
    "M2: il tipo sta barando b* può essere qualsiasi cosa, uniforme tra 0 ed 1\n",
    "\n",
    "Given a bunch of data points, quale conclusione posso trarre? Nota che sto tirando fuori conoscenza sulla mia prior, dai dati!\n",
    "\n",
    "Faccio il mio odds ratio, vedo cosa succede. La mia possibilità di capire cosa sta succedendo migliora con la sample size! ( Per credere DAVVERO che la moneta sia fair vs. non sapere niente, devi lanciare la moneta almeno 157 volte ).\n",
    "\n",
    "Riascolta come interpreta il grafico :°\n",
    "\n",
    "### Approximate Bayesian Model comparison\n",
    "\n",
    "Fare l'odds ratio a volte è un casino. Usiamo dei \"surrogati\" più semplici per semplificare la nostra vita.\n",
    "\n",
    "-> AIC è un sano modo alternativo, l'abbiamo già visto.\n",
    "\n",
    "-> BIC: minimizzato quando il modello è preferito, si basa sulla massima verosigmiglianza.\n",
    "\n",
    "> Questi criteri possono fallire molto facilmente se hai un trivial number of parameters, attenzione!\n",
    "\n",
    "Il rasoio di Occam è implementato automaticamente in BIC con la $k \\ lnN$. \n",
    "\n",
    "Bottom line: CALCOLA L'ODDS RATIO OGNI VOLTA CHE PUOI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
