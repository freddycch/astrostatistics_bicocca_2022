{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nested Sampling\n",
    "\n",
    "E' un altro modo per mappare le posterior. Basically, è un modo per calcolare l'*evidence*, ma la posterior è un utile byproduct!\n",
    "\n",
    "Obiettivo: compare and test models. \n",
    "\n",
    "Problema: compute the evidence! Come si fa?\n",
    "\n",
    "Primo esempio: **savage-dickey approximation**\n",
    "\n",
    "Vuoi testare modelli NESTED WITH EACH OTHER. Es. vuoi testare la massa del Gravitone. Ha zero o non ha zero? ( sono due teorie diverse ) -> il caso in cui m=0 è un caso SPECIFICO della massa \"generica\". <br> In questo caso, puoi usare dei \"naive\" MCMCs per mappare il full parameter space ( quello del modello \"più grande\" ) e ne fai una *slice*: prendi solo i dati \"vicini\" al tuo modello \"più piccolo\", e fai l'odds ratio.\n",
    "\n",
    "Secondo metodo: **product-space sampling**\n",
    "\n",
    "Molto usato in astrophysics. NON cerchi di valutare l'evidence *at all*. Aggiungo un parametro al mio problema ( vedi esempio del Gerry ) e il mio sampler \"salta\" da un problema all'altro. Esploro due likelihood, e poi faccio il ratio dei sampler. A quel punto il ratio delle evidence è il ratio dai due! ( Il sampler \"preferisce\" stare dove la posterior è più grande. )\n",
    "\n",
    "Terzo metodo: **thermodynamic integration**\n",
    "\n",
    "Strategia: il sampler \"sampla\" la likelihood con diversi livelli di smoothness.\n",
    "\n",
    "---\n",
    "\n",
    "NESTED SAMPLING: parto con diversi punti (*live-points*) dalla prior, ci valuti la likelihood. Aggiungi alla posterior qualcosa, hai un qualche salto e da quel che ho capito rimuovi i punti con la likelihood più bassa. (?) (?) (?) Il notebook è scritto bene, leggilo.\n",
    "\n",
    "L'evidence integral quindi si trasforma in un integrale della likelihood! ( praticamente dalla tua funzione hai una funzione \"sopra\" una certa soglia )\n",
    "\n",
    "Guarda l'algoritmo: praticamente a ogni iterazione guadagni una fetta di volume w_i * L_i!\n",
    "\n",
    "Documentazione: di solito si usano MultiNest e PyMultiNest (più potente, ma menoso da installare)\n",
    "\n",
    "In tal proposito, guardiamo **dynesty**.\n",
    "\n",
    "Vedi notebook. NON scrivi la prior vera e propria, bensì il modo in cui devi estrarre i numeri dalla prior!\n",
    "\n",
    "L'analogo dei trace plots è quello che vediamo sotto. All'inizio i live points sono spalmati in giro, poi vanno a convergere verso il top della L. Il pezzo in giallo è quello in cui guadagno di più.\n",
    "\n",
    "Corner plot: vedo correlazione tra i dati, infatti ho ellissi allungate e non cerchi.\n",
    "\n",
    "> **Nested sampling provides weighted samples: not all samples are equal, unlike in MCMC! PER QUESTO MOTIVO, NON PUOI INTERROMPERE A META' L'ALGORITMO. <br> Also, do NOT just grab the points and plot them!\n",
    "\n",
    "Dynamic Nested Sampling: \"si accorge da solo\" di dover incrementare il numero di samples da fare prima di fermarsi, per capire se \"converge\" o meno.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
