{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chain Monte Carlo (MCMC)\n",
    "\n",
    "Abbiamo visto Bayesian Inference & Parameter Estimating. \n",
    "\n",
    "Ok, siamo riusciti a fare le cose \"velocemente\" perché abbiamo lavorato su una griglia 100x100 di punti e abbiamo fatto il color-coding. Ok, 100^2 punti in cui calcoli la $L$ e via.\n",
    "\n",
    "Molto bene: cinque dimensioni? Algoritmi complicati? *Auguri!* -> Unfeasible\n",
    "\n",
    "Alternativa: randomly sample the grid? -> Suboptimal, perdi punti. \n",
    "\n",
    "Modo migliore: design a strategy that samples the posterior in a way that is proportional to the posterior itself! E QUESTO E' IL VERO CORE DELLA BAYESIAN ANALYSIS\n",
    "\n",
    "=> MARKOV-CHAIN MONTE CARLO è una soluzione. ( c'è anche Nested Sampling )\n",
    "\n",
    "---\n",
    "\n",
    "Prova a calcolare $\\pi$ in N dimensioni, come fa lui nel notebook! Volume di una sfera N-dimensionale = ?\n",
    "\n",
    "---\n",
    "\n",
    "Back to business. What is $MCMC$?\n",
    "\n",
    "It is a chain ( step process ), that only depends on the *previous* step.\n",
    "In altre parole, $p(\\theta_{i+1}|\\theta_i, \\theta_{i-1}, \\theta_{i-2}, \\cdots) = p(\\theta_{i+1}|\\theta_i).$\n",
    "\n",
    "Voglio equilibrio => la mia probabilità di andare \"in avanti\" è uguale ad andare \"indietro\".\n",
    "\n",
    "$$    p(\\theta_{i+1}|\\,\\theta_i) = p(\\theta_i |\\, \\theta_{i+1}). $$\n",
    "\n",
    "This is called the ***principle of detailed balance*** or reversibility condition (i.e. the probability of a jump between two points does not depend on the direction of the jump).\n",
    "\n",
    "> Time to get your hands dirty: planning a telescope observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, e ora usiamo i MCMC per calcolare gli integrali. \n",
    "\n",
    "Hai notato che la nostra MCMC deve \"termalizzarsi\" e raggiungere una sorta di equilibrio attorno ad un punto stazionario ( tipo plateau nell'esercizio ). In generale, posso dire che $$ p(\\theta_{i+1}) = \\int  T(\\theta_{i+1}|\\theta_i)  \\,   p(\\theta_i) \\,    d \\theta_i, $$ where the transition probability $T(\\theta_{i+1}|\\theta_i)$ is called the **proposal distribution** (and it is assumed that we know how to compute $p(\\theta_i)$). The proposal distribution is exactly what it sounds like-- it proposes new positions to jump to in parameter space. <br> This requirement will be satisfied when the transition probability satisfies **the principle of detailed balance** $$ T(\\theta_{i+1}|\\theta_i)  \\,  p(\\theta_i) = T(\\theta_i|\\theta_{i+1})  \\,  p(\\theta_{i+1}). $$\n",
    "\n",
    "Sono su un punto nel parameter space: qual è la probabilità di saltare su un altro punto? Guardo la *density of points*, ed è più probabile \"cadere\" su quei punti.\n",
    "\n",
    "###### Metropolis-Hastings Algorithm\n",
    "\n",
    "Voglio density proporzionale alla posterior itself: allora uso probability of acceptance ( non è una vera e propria probabilità, quella che scrive lui ).\n",
    "\n",
    "Mi serve T simmetrica rispetto a $\\theta_{i+i}$ e $\\theta_{i}$ (?)(?)(?).\n",
    "\n",
    "> Crucialmente, c'è un problema: la larghezza del \"salto\".\n",
    "\n",
    "Start from initial guess -> Imprint a memory in the chain, removed later on -> Estraggo il theta successivo -> Valuto la probabilità di i+1. -> Accetto il punto o meno, basandomi su quella probabilità -> Se lo accetto, lo aggiungo alla catena e ci vado // Se lo rifiuto, sto su theta_i e rifaccio con un altro theta_i.\n",
    "\n",
    "( Voglio anche minimizzare il numero di likelihood calls )\n",
    "\n",
    "Nota che il punto $4$ dell'elenco è cruciale! A volte NON vuoi andare sul massimo, ma vuoi \"guardare anche in giro\"!\n",
    "\n",
    "---\n",
    "##### Esempio \"svolto\" di MCMC\n",
    "\n",
    "Nota che in *sampler* NON sta mappando la evidence!\n",
    "\n",
    "Il trace plot per un \"good\" MCMC run è mostrato nel blocco sotto. La chain ha lo stesso aspetto WHEREVER I look at it. \n",
    "\n",
    "Supponiamo ora che il proposal jump sia *tiny*: what could go wrong? Supponiamo invece che il proposal jump sia *big*: di nuovo, salto troppo lontano e mappo male tutto (succede, soprattutto se hai più picchi che vuoi 'esplorare'); appena trovi un picco, ti inchiodi lì e rifiuti tutto.\n",
    "\n",
    "---\n",
    "\n",
    "Ideally, our traceplot in each parameter would be **mixing well** (moving across parameter space without getting stuck), and carving out the same patch of parameter space on average. **The acceptance rate of new samples should be somewhere between $\\sim20-50\\%$ depending on the type of problem you're trying to solve**. (Gerry non è troppo d'accordo.)\n",
    "\n",
    "Guarda l'immagine \"di là\" sul notebook: tiny proposal, big proposal, \"right\" proposal.\n",
    "\n",
    "> Trovare il \"salto\" giusto è cruciale per riuscire a fare un buon MCMC.\n",
    "\n",
    "> CRUCIALE: TUTTO QUEL CHE HAI, SONO I SAMPLE. **NON HAI LA PDF SU UNA GRIGLIA**: LA DENSITA' DEI PUNTI NELLO SPAZIO DEI PARAMETRI, TI FA TIRARE FUORI LA POSTERIOR -> Density Estimation algorithm. **MCMC => Density Estimation afterwards.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
